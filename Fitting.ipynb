{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly as py\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,roc_auc_score\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import torch \n",
    "torch.manual_seed(0) \n",
    "import gpytorch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12316, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>154.216667</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0             0.0                      0.0            0.0   \n",
       "1             0.0                      0.0            0.0   \n",
       "2             0.0                     -1.0            0.0   \n",
       "3             0.0                      0.0            0.0   \n",
       "4             0.0                      0.0            0.0   \n",
       "5             0.0                      0.0            0.0   \n",
       "6             0.0                     -1.0            0.0   \n",
       "7             1.0                     -1.0            0.0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0             1.0                 0.000000   \n",
       "1                     0.0             2.0                64.000000   \n",
       "2                    -1.0             1.0                -1.000000   \n",
       "3                     0.0             2.0                 2.666667   \n",
       "4                     0.0            10.0               627.500000   \n",
       "5                     0.0            19.0               154.216667   \n",
       "6                    -1.0             1.0                -1.000000   \n",
       "7                    -1.0             1.0                -1.000000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0     0.200000   0.200000         0.0         0.0   Feb                 1   \n",
       "1     0.000000   0.100000         0.0         0.0   Feb                 2   \n",
       "2     0.200000   0.200000         0.0         0.0   Feb                 4   \n",
       "3     0.050000   0.140000         0.0         0.0   Feb                 3   \n",
       "4     0.020000   0.050000         0.0         0.0   Feb                 3   \n",
       "5     0.015789   0.024561         0.0         0.0   Feb                 2   \n",
       "6     0.200000   0.200000         0.0         0.4   Feb                 2   \n",
       "7     0.200000   0.200000         0.0         0.0   Feb                 1   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  \n",
       "5        2       1            3  Returning_Visitor    False    False  \n",
       "6        4       3            3  Returning_Visitor    False    False  \n",
       "7        2       1            5  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the dataset\n",
    "\n",
    "data = pd.read_csv('online_shoppers_intention.csv')\n",
    "data.dropna(inplace=True)\n",
    "print(data.shape)\n",
    "data.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.317798</td>\n",
       "      <td>80.906176</td>\n",
       "      <td>0.503979</td>\n",
       "      <td>34.506387</td>\n",
       "      <td>31.763884</td>\n",
       "      <td>1196.037057</td>\n",
       "      <td>0.022152</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>5.895952</td>\n",
       "      <td>0.061497</td>\n",
       "      <td>2.124147</td>\n",
       "      <td>2.357584</td>\n",
       "      <td>3.148019</td>\n",
       "      <td>4.070477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.322754</td>\n",
       "      <td>176.860432</td>\n",
       "      <td>1.270701</td>\n",
       "      <td>140.825479</td>\n",
       "      <td>44.490339</td>\n",
       "      <td>1914.372511</td>\n",
       "      <td>0.048427</td>\n",
       "      <td>0.048527</td>\n",
       "      <td>18.577926</td>\n",
       "      <td>0.199020</td>\n",
       "      <td>0.911566</td>\n",
       "      <td>1.718028</td>\n",
       "      <td>2.402211</td>\n",
       "      <td>4.024598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>599.766190</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>0.025124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1466.479902</td>\n",
       "      <td>0.016684</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>3398.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2549.375000</td>\n",
       "      <td>705.000000</td>\n",
       "      <td>63973.522230</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>361.763742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Administrative  Administrative_Duration  Informational  \\\n",
       "count    12316.000000             12316.000000   12316.000000   \n",
       "mean         2.317798                80.906176       0.503979   \n",
       "std          3.322754               176.860432       1.270701   \n",
       "min          0.000000                -1.000000       0.000000   \n",
       "25%          0.000000                 0.000000       0.000000   \n",
       "50%          1.000000                 8.000000       0.000000   \n",
       "75%          4.000000                93.500000       0.000000   \n",
       "max         27.000000              3398.750000      24.000000   \n",
       "\n",
       "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "count            12316.000000    12316.000000             12316.000000   \n",
       "mean                34.506387       31.763884              1196.037057   \n",
       "std                140.825479       44.490339              1914.372511   \n",
       "min                 -1.000000        0.000000                -1.000000   \n",
       "25%                  0.000000        7.000000               185.000000   \n",
       "50%                  0.000000       18.000000               599.766190   \n",
       "75%                  0.000000       38.000000              1466.479902   \n",
       "max               2549.375000      705.000000             63973.522230   \n",
       "\n",
       "        BounceRates     ExitRates    PageValues    SpecialDay  \\\n",
       "count  12316.000000  12316.000000  12316.000000  12316.000000   \n",
       "mean       0.022152      0.043003      5.895952      0.061497   \n",
       "std        0.048427      0.048527     18.577926      0.199020   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.014286      0.000000      0.000000   \n",
       "50%        0.003119      0.025124      0.000000      0.000000   \n",
       "75%        0.016684      0.050000      0.000000      0.000000   \n",
       "max        0.200000      0.200000    361.763742      1.000000   \n",
       "\n",
       "       OperatingSystems       Browser        Region   TrafficType  \n",
       "count      12316.000000  12316.000000  12316.000000  12316.000000  \n",
       "mean           2.124147      2.357584      3.148019      4.070477  \n",
       "std            0.911566      1.718028      2.402211      4.024598  \n",
       "min            1.000000      1.000000      1.000000      1.000000  \n",
       "25%            2.000000      2.000000      1.000000      2.000000  \n",
       "50%            2.000000      2.000000      3.000000      2.000000  \n",
       "75%            3.000000      2.000000      4.000000      4.000000  \n",
       "max            8.000000     13.000000      9.000000     20.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    10408\n",
       "1     1908\n",
       "Name: Revenue, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.isnull().sum().sum())\n",
    "data = pd.get_dummies(data)\n",
    "le = LabelEncoder()\n",
    "data['Revenue'] = le.fit_transform(data['Revenue'])\n",
    "data['Revenue'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Administrative                   float64\n",
       "Administrative_Duration          float64\n",
       "Informational                    float64\n",
       "Informational_Duration           float64\n",
       "ProductRelated                   float64\n",
       "ProductRelated_Duration          float64\n",
       "BounceRates                      float64\n",
       "ExitRates                        float64\n",
       "PageValues                       float64\n",
       "SpecialDay                       float64\n",
       "OperatingSystems                   int64\n",
       "Browser                            int64\n",
       "Region                             int64\n",
       "TrafficType                        int64\n",
       "Weekend                             bool\n",
       "Revenue                            int64\n",
       "Month_Aug                          uint8\n",
       "Month_Dec                          uint8\n",
       "Month_Feb                          uint8\n",
       "Month_Jul                          uint8\n",
       "Month_June                         uint8\n",
       "Month_Mar                          uint8\n",
       "Month_May                          uint8\n",
       "Month_Nov                          uint8\n",
       "Month_Oct                          uint8\n",
       "Month_Sep                          uint8\n",
       "VisitorType_New_Visitor            uint8\n",
       "VisitorType_Other                  uint8\n",
       "VisitorType_Returning_Visitor      uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/harsh/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/harsh/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/harsh/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/harsh/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/harsh/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/harsh/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/harsh/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/harsh/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/harsh/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/harsh/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/harsh/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/harsh/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y = x_resampled,y_resampled\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 0)\n",
    "# print(\"Shape of x_train :\", x_train.shape)\n",
    "# print(\"Shape of y_train :\", y_train.shape)\n",
    "# print(\"Shape of x_test :\", x_test.shape)\n",
    "# print(\"Shape of y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7276\n",
      "Shape of x_train : (8621, 28)\n",
      "Shape of y_train : (8621,)\n",
      "Shape of x_test : (3695, 28)\n",
      "Shape of y_test : (3695,)\n"
     ]
    }
   ],
   "source": [
    "x=data\n",
    "x = x.drop(['Revenue'], axis = 1)\n",
    "y = data['Revenue']\n",
    "x = np.array(x).astype(np.float32)\n",
    "y = np.array(y).astype(np.float32)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "y_train[y_train==0] = -1\n",
    "y_train[y_train==1] = 1\n",
    "y_test[y_test==0] = -1\n",
    "y_test[y_test==1] = 1\n",
    "print(np.sum(y_train==-1))\n",
    "# x_train, y_train = SMOTE().fit_resample(x_train, y_train)\n",
    "# x_train, y_train = ADASYN().fit_resample(x_train,y_train)\n",
    "print(\"Shape of x_train :\", x_train.shape)\n",
    "print(\"Shape of y_train :\", y_train.shape)\n",
    "print(\"Shape of x_test :\", x_test.shape)\n",
    "print(\"Shape of y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf_classi = RandomForestClassifier()\n",
    "model_rf = model_rf_classi.fit(x_train,y_train)\n",
    "y_pred_enrf = model_rf.predict(x_test)\n",
    "print(\"\\n Done\")\n",
    "print(\"\\n AUC of Random Forest: \",roc_auc_score(y_test,y_pred_enrf))\n",
    "print(\"Report:\\n\",classification_report(y_test,y_pred_enrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without Oversampling\n",
    "\n",
    "n_est_all = np.arange(5,450,10)\n",
    "scores_all = []\n",
    "for n_est in n_est_all:\n",
    "    print(\"n_est=\",n_est,end='')\n",
    "    model_rf_classi = RandomForestClassifier(n_estimators=n_est,random_state=69)\n",
    "    model_rf = model_rf_classi.fit(x_train,y_train)\n",
    "    y_pred_enrf = model_rf.predict(x_test)\n",
    "    auc_sc = roc_auc_score(y_test,y_pred_enrf)\n",
    "    print(\"auc=\",auc_sc)\n",
    "    scores_all.append(auc_sc)\n",
    "plt.scatter(n_est_all,scores_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With SMOTE\n",
    "\n",
    "n_est_all = np.arange(5,450,10)\n",
    "scores_all = []\n",
    "for n_est in n_est_all:\n",
    "    print(\"n_est=\",n_est,end='')\n",
    "    model_rf_classi = RandomForestClassifier(n_estimators=n_est,random_state=69)\n",
    "    model_rf = model_rf_classi.fit(x_train,y_train)\n",
    "    y_pred_enrf = model_rf.predict(x_test)\n",
    "    auc_sc = roc_auc_score(y_test,y_pred_enrf)\n",
    "    print(\"auc=\",auc_sc)\n",
    "    scores_all.append(auc_sc)\n",
    "plt.scatter(n_est_all,scores_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With ADASYN\n",
    "\n",
    "n_est_all = np.arange(5,450,10)\n",
    "scores_all = []\n",
    "for n_est in n_est_all:\n",
    "    print(\"n_est=\",n_est,end='')\n",
    "    model_rf_classi = RandomForestClassifier(n_estimators=n_est,random_state=69)\n",
    "    model_rf = model_rf_classi.fit(x_train,y_train)\n",
    "    y_pred_enrf = model_rf.predict(x_test)\n",
    "    auc_sc = roc_auc_score(y_test,y_pred_enrf)\n",
    "    print(\"auc=\",auc_sc)\n",
    "    scores_all.append(auc_sc)\n",
    "plt.scatter(n_est_all,scores_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumpos = np.sum(y_train==1)\n",
    "sumneg = np.sum(y_train==-1)\n",
    "print(sumpos,sumneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgmodel = XGBRegressor(n_jobs=-1,scale_pos_weight=sumneg/sumpos,eval_metric='auc')\n",
    "print(xgmodel)\n",
    "xgmodel.fit(x_train,y_train)\n",
    "y_predxg = xgmodel.predict(x_test)\n",
    "print(\"auc=\",roc_auc_score(y_test,y_predxg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_scores = []\n",
    "for n_est in np.arange(10,200,10):\n",
    "    for md in np.arange(1,20,3):        \n",
    "        xgmodel = XGBRegressor(max_depth=md,n_estimators=n_est,n_jobs=-1,random_state=69,)\n",
    "#         print(xgmodel)\n",
    "        xgmodel.fit(x_train,y_train)\n",
    "        y_predxg = xgmodel.predict(x_test)\n",
    "        auc = roc_auc_score(y_test,y_predxg)\n",
    "        print(\"auc=\",auc)\n",
    "        xgb_scores.append(auc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"xgb best auc=\",np.max(xgb_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GP Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 1.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(y_train),np.max(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor(x_train)\n",
    "train_y = torch.tensor(y_train)\n",
    "test_x = torch.tensor(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(ard_num_dims=x_train.shape[1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50 - Loss: 0.955  noise: 0.077\n",
      "Iter 2/50 - Loss: 0.948  noise: 0.070\n",
      "Iter 3/50 - Loss: 0.939  noise: 0.064\n",
      "Iter 4/50 - Loss: 0.929  noise: 0.058\n",
      "Iter 5/50 - Loss: 0.927  noise: 0.052\n",
      "Iter 6/50 - Loss: 0.921  noise: 0.048\n",
      "Iter 7/50 - Loss: 0.910  noise: 0.043\n",
      "Iter 8/50 - Loss: 0.908  noise: 0.039\n",
      "Iter 9/50 - Loss: 0.905  noise: 0.036\n",
      "Iter 10/50 - Loss: 0.901  noise: 0.032\n",
      "Iter 11/50 - Loss: 0.887  noise: 0.029\n",
      "Iter 12/50 - Loss: 0.878  noise: 0.027\n",
      "Iter 13/50 - Loss: 0.880  noise: 0.024\n",
      "Iter 14/50 - Loss: 0.868  noise: 0.022\n",
      "Iter 15/50 - Loss: 0.865  noise: 0.020\n",
      "Iter 16/50 - Loss: 0.866  noise: 0.019\n",
      "Iter 17/50 - Loss: 0.860  noise: 0.017\n",
      "Iter 18/50 - Loss: 0.859  noise: 0.015\n",
      "Iter 19/50 - Loss: 0.848  noise: 0.014\n",
      "Iter 20/50 - Loss: 0.844  noise: 0.013\n",
      "Iter 21/50 - Loss: 0.847  noise: 0.012\n",
      "Iter 22/50 - Loss: 0.837  noise: 0.011\n",
      "Iter 23/50 - Loss: 0.834  noise: 0.010\n",
      "Iter 24/50 - Loss: 0.831  noise: 0.009\n",
      "Iter 25/50 - Loss: 0.833  noise: 0.009\n",
      "Iter 26/50 - Loss: 0.831  noise: 0.008\n",
      "Iter 27/50 - Loss: 0.828  noise: 0.007\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-37ba73dc305b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Calc loss and backprop gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     print('Iter %d/%d - Loss: %.3f  noise: %.3f' % (\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Add additional terms (SGPR / learned inducing points, heteroskedastic likelihood models)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Get log determininat and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36minv_quad_logdet\u001b[0;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[1;32m   1036\u001b[0m                 )\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minv_quad_rhs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mrepresentation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1266\u001b[0m                 \u001b[0mrepresentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"representation\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Is it a LazyTensor?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mrepresentation\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Representation of a LazyTensor should consist only of Tensors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mrepresentation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcache_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0madd_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mevaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mtemp_active_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_active_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/kernels/kernel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLazyEvaluatedKernelTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/kernels/scale_kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, last_dim_is_batch, diag, **params)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0moutputscales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputscales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moutputscales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0morig_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputscales\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnum_outputs_per_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "training_iter = 50\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f  noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        model.likelihood.noise.item()\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "# y_preds = model(test_x).mean\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.max_cg_iterations(2000), gpytorch.settings.fast_pred_var():\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "    \n",
    "#     observed_pred = model(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 15.0995, -21.1579,  -0.4769,  ..., -68.9148,   0.0912,  -0.4799])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_pred.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 15.099534   -21.15795     -0.47692287 ... -68.91479      0.09115395\n",
      "  -0.4799435 ]\n",
      "-427.1869\n",
      "281.94275\n",
      "-0.48010454\n"
     ]
    }
   ],
   "source": [
    "y_preds = observed_pred.mean.detach().numpy().copy()\n",
    "print(y_preds)\n",
    "print(np.min(y_preds))\n",
    "print(np.max(y_preds))\n",
    "print(np.median(y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f078e1fe780>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.scatter(np.arange(len(y_test)),y_test)\n",
    "plt.scatter(np.arange(len(y_preds)),y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds[y_preds<-1] = -1\n",
    "y_preds[y_preds>1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6131093349121768\n"
     ]
    }
   ],
   "source": [
    "# y_preds = y_preds.detach().numpy()\n",
    "# y_pred = y_preds.copy()\n",
    "# y_pred[y_pred>=0] = 1\n",
    "# y_pred[y_pred<0] = -1\n",
    "# print(\"Report : \\n\", classification_report(y_test, y_preds))\n",
    "print(\"AUC: \", roc_auc_score(y_test,y_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import gpytorch\n",
    "from torch.nn import Linear\n",
    "from gpytorch.means import ConstantMean, LinearMean\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.variational import VariationalStrategy, CholeskyVariationalDistribution\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.models import ApproximateGP, GP\n",
    "from gpytorch.mlls import VariationalELBO, AddedLossTerm\n",
    "from gpytorch.likelihoods import GaussianLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models.deep_gps import DeepGPLayer, DeepGP\n",
    "from gpytorch.mlls import DeepApproximateMLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor(x_train)\n",
    "train_y = torch.tensor(y_train)\n",
    "test_x = torch.tensor(x_test)\n",
    "test_y = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDeepGPHiddenLayer(DeepGPLayer):\n",
    "    def __init__(self, input_dims, output_dims, num_inducing=128, mean_type='constant'):\n",
    "        if output_dims is None:\n",
    "            inducing_points = torch.randn(num_inducing, input_dims)\n",
    "            batch_shape = torch.Size([])\n",
    "        else:\n",
    "            inducing_points = torch.randn(output_dims, num_inducing, input_dims)\n",
    "            batch_shape = torch.Size([output_dims])\n",
    "\n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            num_inducing_points=num_inducing,\n",
    "            batch_shape=batch_shape\n",
    "        )\n",
    "\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self,\n",
    "            inducing_points,\n",
    "            variational_distribution,\n",
    "            learn_inducing_locations=True\n",
    "        )\n",
    "\n",
    "        super(ToyDeepGPHiddenLayer, self).__init__(variational_strategy, input_dims, output_dims)\n",
    "\n",
    "        if mean_type == 'constant':\n",
    "            self.mean_module = ConstantMean(batch_shape=batch_shape)\n",
    "        else:\n",
    "            self.mean_module = LinearMean(input_dims)\n",
    "        self.covar_module = ScaleKernel(\n",
    "            RBFKernel(batch_shape=batch_shape, ard_num_dims=input_dims),\n",
    "            batch_shape=batch_shape, ard_num_dims=None\n",
    "        )\n",
    "\n",
    "        self.linear_layer = Linear(input_dims, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x) # self.linear_layer(x).squeeze(-1)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "    def __call__(self, x, *other_inputs, **kwargs):\n",
    "        \"\"\"\n",
    "        Overriding __call__ isn't strictly necessary, but it lets us add concatenation based skip connections\n",
    "        easily. For example, hidden_layer2(hidden_layer1_outputs, inputs) will pass the concatenation of the first\n",
    "        hidden layer's outputs and the input data to hidden_layer2.\n",
    "        \"\"\"\n",
    "        if len(other_inputs):\n",
    "            if isinstance(x, gpytorch.distributions.MultitaskMultivariateNormal):\n",
    "                x = x.rsample()\n",
    "\n",
    "            processed_inputs = [\n",
    "                inp.unsqueeze(0).expand(self.num_samples, *inp.shape)\n",
    "                for inp in other_inputs\n",
    "            ]\n",
    "\n",
    "            x = torch.cat([x] + processed_inputs, dim=-1)\n",
    "\n",
    "        return super().__call__(x, are_samples=bool(len(other_inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output_dims = 1\n",
    "\n",
    "\n",
    "class DeepGP(DeepGP):\n",
    "    def __init__(self, train_x_shape):\n",
    "        hidden_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=train_x_shape[-1],\n",
    "            output_dims=num_output_dims,\n",
    "            mean_type='linear',\n",
    "        )\n",
    "\n",
    "        last_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=hidden_layer.output_dims,\n",
    "            output_dims=None,\n",
    "            mean_type='constant',\n",
    "        )\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.last_layer = last_layer\n",
    "        self.likelihood = GaussianLikelihood()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        hidden_rep1 = self.hidden_layer(inputs)\n",
    "        output = self.last_layer(hidden_rep1)\n",
    "        return output\n",
    "\n",
    "    def predict(self, test_loader):\n",
    "        with torch.no_grad():\n",
    "            mus = []\n",
    "            variances = []\n",
    "            lls = []\n",
    "            for x_batch, y_batch in test_loader:\n",
    "                preds = model.likelihood(model(x_batch))\n",
    "                mus.append(preds.mean)\n",
    "                variances.append(preds.variance)\n",
    "                lls.append(model.likelihood.log_marginal(y_batch, model(x_batch)))\n",
    "\n",
    "        return torch.cat(mus, dim=-1), torch.cat(variances, dim=-1), torch.cat(lls, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepGP(train_x.shape)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning:\n",
      "\n",
      "This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90d3937538f4b01abba6037b795d111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning:\n",
      "\n",
      "This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Minibatch', max=9.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "num_epochs = 1 \n",
    "num_samples = 3 \n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "], lr=0.01)\n",
    "mll = DeepApproximateMLL(VariationalELBO(model.likelihood, model, train_x.shape[-2]))\n",
    "\n",
    "epochs_iter = tqdm.tqdm_notebook(range(num_epochs), desc=\"Epoch\")\n",
    "for i in epochs_iter:\n",
    "    # Within each iteration, we will go over each minibatch of data\n",
    "    minibatch_iter = tqdm.tqdm_notebook(train_loader, desc=\"Minibatch\", leave=False)\n",
    "    for x_batch, y_batch in minibatch_iter:\n",
    "        with gpytorch.settings.num_likelihood_samples(num_samples):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = -mll(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            minibatch_iter.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0891, -0.0891, -0.0891,  ..., -0.0891, -0.0891, -0.0891],\n",
      "        [-0.0891, -0.0891, -0.0891,  ..., -0.0891, -0.0891, -0.0891],\n",
      "        [-0.0891, -0.0891, -0.0891,  ..., -0.0891, -0.0891, -0.0891],\n",
      "        ...,\n",
      "        [-0.0891, -0.0891, -0.0891,  ..., -0.0891, -0.0891, -0.0891],\n",
      "        [-0.0891, -0.0891, -0.0891,  ..., -0.0891, -0.0891, -0.0891],\n",
      "        [-0.0891, -0.0891, -0.0891,  ..., -0.0891, -0.0891, -0.0891]])\n",
      "RMSE: 0.935727596282959, NLL: 1.3964754343032837\n"
     ]
    }
   ],
   "source": [
    "import gpytorch\n",
    "import math\n",
    "\n",
    "\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024)\n",
    "\n",
    "model.eval()\n",
    "predictive_means, predictive_variances, test_lls = model.predict(test_loader)\n",
    "print(predictive_means)\n",
    "rmse = torch.mean(torch.pow(predictive_means.mean(0) - test_y, 2)).sqrt()\n",
    "print(f\"RMSE: {rmse.item()}, NLL: {-test_lls.mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
